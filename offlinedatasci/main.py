#Creating directory for R files if it does not exist
# Download files using download files.py
#Downloading Data Carpentry website using httrack

from pathlib import Path
import bs4 as bs
import os
import re
import subprocess
import urllib.request, urllib.error, urllib.parse
import pkg_resources
import pypi_mirror
import shutil
import sys
import warnings

def download_and_save_installer(latest_version_url, destination_path):
    """Download and save installer in user given path.

    Keyword arguments:
    latest_version_url -- Link to download installer
    destination_path -- Path to save installer
    """
    if not os.path.exists(destination_path):
                print("****Downloading file: ", destination_path)    
                urllib.request.urlretrieve(latest_version_url, destination_path) 
    else:
        print("File not being downloaded")


def download_r(destination_path):
    """Download most recent version of R installer (mac and windows) from CRAN

    Keyword arguments:
    destination_path -- Path to save installers
    """
    latest_version_url_win = "https://cran.r-project.org/bin/windows/base/release.html"
    latest_version_url_mac = "https://cran.r-project.org/bin/macosx/"

    download_r_most_current_ver(latest_version_url_win, destination_path)
    download_r_most_current_ver(latest_version_url_mac, destination_path)


def download_lessons(ods_dir):
    """Downloads the workshop lessons as rendered HTML.
    Keyword arguments:
    destination_path -- Path to save rendered HTML lessons
    """

    if not shutil.which('wget'):
        warnings.warn("""wget not detected so not downloading lessons.

        wget needs to be installed on your computer to clone lesson websites.

        macOS: you can install wget using Xcode command line tools
               or using `conda install wget -c conda-forge` if you are using conda.
        
        Windows: you can download a wget binary from: https://eternallybored.org/misc/wget/
        """)
        return

    dc_lessons = ["https://datacarpentry.org/ecology-workshop/",
                  "https://datacarpentry.org/spreadsheet-ecology-lesson/",
                  "http://datacarpentry.org/OpenRefine-ecology-lesson/",
                  "https://datacarpentry.org/R-ecology-lesson/",
                  "https://datacarpentry.org/python-ecology-lesson/",
                  "https://datacarpentry.org/sql-ecology-lesson/"]
    lc_lessons = ["https://librarycarpentry.org/lc-overview/",
                  "https://librarycarpentry.org/lc-data-intro/",
                  "https://librarycarpentry.org/lc-shell/",
                  "https://librarycarpentry.org/lc-open-refine/",
                  "https://librarycarpentry.org/lc-git/",
                  ]

    for lesson in dc_lessons + lc_lessons:
        print(f"Downloading lesson from {lesson}")
        subprocess.run(["wget", "-r", "-k", "-N", "-c", "--no-parent", "-P", ods_dir, lesson],
                       stdout=subprocess.DEVNULL,
                       stderr=subprocess.STDOUT)

    sc_lessons = ["http://swcarpentry.github.io/shell-novice",
                  "http://swcarpentry.github.io/git-novice",
                  "http://swcarpentry.github.io/python-novice-inflammation",
                  "http://swcarpentry.github.io/python-novice-gapminder",
                  "http://swcarpentry.github.io/r-novice-inflammation",
                  "http://swcarpentry.github.io/r-novice-gapminder",
                  "http://swcarpentry.github.io/shell-novice-es",
                  "http://swcarpentry.github.io/git-novice-es",
                  "http://swcarpentry.github.io/r-novice-gapminder-es"]

    # Software Carpentry lessons have external CSS so requires a more expansive search & rewriting to get all necessary files
    for lesson in sc_lessons:
        print(f"Downloading lesson from {lesson}")
        subprocess.run(["wget", "-p", "-r", "-k", "-N", "-c", "-E", "-H", "-D", "swcarpentry.github.io", "-K", "--no-parent", "-P", ods_dir, lesson],
                       stdout = subprocess.DEVNULL,
                       stderr = subprocess.STDOUT)

def download_rstudio(ods_dir):
    """Download RStudio installers"""
    baseurl = 'https://www.rstudio.com/products/rstudio/download/#download'
    destination_path = Path(Path(ods_dir), Path("rstudio"))
    if not os.path.isdir(destination_path):
        os.makedirs(destination_path)
    fp = urllib.request.urlopen(baseurl)
    web_content = fp.read()
    soup = bs.BeautifulSoup(web_content, 'lxml')
    links = soup.find_all('a')
    for link in links:
        if link.has_attr('href') and (".exe" in link['href'] or ".dmg" in link['href']):
            url = str(link['href'])
            download_and_save_installer(url, Path(Path(destination_path), Path(os.path.basename(url))))

def download_python(ods_dir):
    """Download Python installers from HTML page

    Keyword arguments:
    ods_dir -- Directory to save installers
    """
    url = get_python_download_page()
    download_table_num=0
    oscolnum=1
    hrefcolnum=0
    key="version"

    destination_path = Path(Path(ods_dir), Path("python"))
    if not os.path.isdir(destination_path):
        os.makedirs(destination_path)
    python_versions = {}
    fp = urllib.request.urlopen(url)
    web_content = fp.read()
    soup = bs.BeautifulSoup(web_content, 'lxml')
    r_studio_download_table = soup.find_all('table')[download_table_num]
    table_body = r_studio_download_table.find('tbody')
    python_versions = {}
    for row in table_body.find_all("tr"):
      os_data = table_parse_version_info(row,oscolnum,hrefcolnum)
      os_version = os_data[key] 
      python_versions[os_version] = os_data
    for key in python_versions.keys():
        is_windows = "embeddable" not in key and "help" not in key and key.startswith("Windows")
        is_macos = key.startswith("macOS")
        if (is_macos or is_windows):
          download_link = python_versions[key]["url"]
          destination_path2 = Path(Path(destination_path), Path(os.path.basename(download_link)))
          download_and_save_installer(download_link, destination_path2)

def download_r_most_current_ver(url, ods_dir):
    """Determine and download most recent version of R installer (mac and windows) from CRAN.

    Keyword arguments:
    url -- CRAN r-project URL
    ods_dir -- Directory to save R installers
    """
    # This regex will help find latest version for mac or windows
    # Format: R-4.1.2.pkg or R-4.1.2-win.exe
    version_regex = "(R\-\d+\.\d+\.\d+(?:\-[a-zA-Z]+)?\.(?:exe|pkg))"
    urlfile = urllib.request.urlopen(url)
    for line in urlfile:
        decoded = line.decode("utf-8") 
        match = re.findall(version_regex, decoded)
        if (match):
            r_current_version = match
            if r_current_version[0].endswith(".exe"):
                baseurl = "https://cran.r-project.org/bin/windows/base/"
                download_paths = [baseurl + r_current_version[0]]
            elif r_current_version[0].endswith('.pkg'):
                baseurl = "https://cran.r-project.org/bin/macosx/"
                download_paths = [baseurl + "big-sur-arm64/base/" + r_current_version[0].strip(".pkg") + "-arm64.pkg",
                                  baseurl + "big-sur-x86_64/base/" + r_current_version[0].strip(".pkg") + "-x86_64.pkg"]
            destination_path = Path(Path(ods_dir), Path("R"))
            if not os.path.isdir(destination_path):
                os.makedirs(destination_path)

            for download_path in download_paths:
                destination_path2 = Path(Path(ods_dir), Path("R"), Path(r_current_version[0]))
                print("\nDestination: ", destination_path2, "\nDownload path: ", download_path)
                if not os.path.exists(destination_path2):
                    print("****Downloading file: ", destination_path2)
                    urllib.request.urlretrieve(download_path, destination_path2)
            break
def get_ods_dir(directory=Path.home()):
    """Get path to save downloads, create if it does not exist.

    Keyword arguments:
    directory -- Path to save downloads (defaults to user home path)
    """
    folder_path = Path(directory)
    if not folder_path.is_dir():
        print("\nCreating ods folder in " + str(directory))
        Path.mkdir(folder_path, parents=True)
    return str(folder_path)

def get_python_download_page():
    """Get download page from Python homepage."""
    base_url="https://www.python.org"
    fp = urllib.request.urlopen(base_url)
    web_content = fp.read()
    soup = bs.BeautifulSoup(web_content, "html.parser")
    release_a_tag = soup.find("a", href=lambda href: href and "release" in href)
    current_release_path = release_a_tag["href"]
    current_release_url = base_url + current_release_path
    return(current_release_url)

def table_parse_version_info(row,oscolnum,hrefcolnum):
    """Parse and return software information from table.

    Keyword arguments:
    row -- Row from HTML table
    oscolnum -- Number of column in which OS is found
    hrefcolnum -- Number of column in which HREFs are found
    """
    # OS / LINK / SIZE / SHA-256
    columns = row.find_all("td") # find all columns in row
    os = columns[oscolnum].text.strip() # return first column data (OS)
    link = columns[hrefcolnum].a # return second column data (href) and access atag with href
    link_url = link['href'].strip()
    link_inner_html = link.text.strip()
    return {"osver": os, "version": link_inner_html, "url": link_url}        

def download_minicran(ods_dir,py_library_reqs = ["tidyverse", "RSQLite"]):
    """Creating partial CRAN mirror of workshop libraries.

    Keyword arguments:
    ods_dir -- Directory to create CRAN mirror
    """
    if not shutil.which('Rscript'):
        warnings.warn("""Rscript not detected so not installing miniCRAN.

        R needs to be installed on your computer to clone lesson websites.

        Install R from: https://cran.r-project.org/
        """)
        return
    minicranpath = pkg_resources.resource_filename("offlinedatasci", "miniCran.R")
    custom_library_string = ' '.join(py_library_reqs)
    subprocess.run(["Rscript", minicranpath, ods_dir, custom_library_string])


def download_python_libraries(ods_dir,py_library_reqs = [ "matplotlib", "notebook","numpy", "pandas"] ):
    """Creating partial PyPI mirror of workshop libraries.

    Keyword arguments:
    ods_dir -- Directory to save partial Pypi mirror
    """
    #workshop_needed_libraries = pandas, matplotlib, numpy
    #python_included_libraries = math, random, glob, time, sys, pathlib
    download_dir = Path(Path(ods_dir), Path("pythonlibraries"))
    pypi_dir = Path(Path(ods_dir), Path("pypi"))
    parameters = {
        'pip': 'pip3',
        'dest': download_dir,
        'pkgs': py_library_reqs,
        'python_version': '3.11',
        'allow_binary': True
    }
    pypi_mirror.download(platform = ['manylinux_2_17_x86_64'], **parameters)
    pypi_mirror.download(platform = ['macosx_10_12_x86_64'], **parameters)
    pypi_mirror.download(platform = ['win_amd64'], **parameters)
    mirror_creation_parameters = {
        'download_dir': download_dir,
        'mirror_dir': pypi_dir,
        'copy': True
    }
    pypi_mirror.create_mirror(**mirror_creation_parameters)

def get_default_packages(language):
    packages = { 
        "r": {
            "data-carpentry": ["tidyverse", "RSQLite"],
            "data-science": ["dplyr", "ggplot2", "shiny", "lubridate", "knitr", "esquisse", "mlr3", "knitr", "DT"]
        },
        "python": {
            "data-carpentry": ["pandas", "notebook", "numpy", "matplotlib", "plotnine"], 
            "software-carpentry": ["matplotlib", "notebook", "numpy", "pandas"] ,
            "data-science": ["scipy", "numpy", "pandas", "matplotlib", "keras", "scikit-learn", "beautifulsoup4", "seaborn","torch"]
        }
    }
    return packages[language]


def package_selection(language, custom_package_list):
    language_dictionary = get_default_packages(language)
    packages_to_download = []
    for item in custom_package_list:
        if item in [*language_dictionary]:
            packages_to_download.extend(language_dictionary[item])
        else:
            packages_to_download.append(item)
    packages_to_download = list(set(packages_to_download))
    return packages_to_download

def try_except_functions(input,functions):
    if not isinstance(functions, list):
        functions = [functions]
    for function in functions:
        try:
            function(input)
        except Exception as e:
            print( f"Error in function: {function.__name__}. Error: {str(e)}")